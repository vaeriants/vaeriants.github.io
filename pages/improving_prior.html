<!DOCTYPE html>
<html lang="en-us">
  <head>
  <meta charset="UTF-8">
  <title>VAEriants</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="theme-color" content="#157878">
  <link rel="stylesheet" href="/css/normalize.css">
  <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
  <link rel="stylesheet" href="/css/cayman.css">
  <script type="text/javascript" 
    src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML">
	MathJax.Hub.Config({
	  tex2jax: {
		displayMath: [ ['$$','$$'], ['\[','\]'] ],
		inlineMath: [['$','$'], ['\\(','\\)']],
		processEscapes: true
	  }
	});

  </script>
</head>

  <body>
  <section class="post-header">
	<img src="/assets/mila_logo_fr.svg">
	<a href="/" class="project-name">VAEriants</a>
</section>
<div style="display:none">

$$
\newcommand{\R}{\mathbb{R}}
\newcommand{\D}{\mathcal{D}}
\newcommand{\X}{\mathcal{X}}
\newcommand{\Y}{\mathcal{Y}}
\newcommand{\h}{h}
\newcommand{\N}{\mathcal{N}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\ELBO}{\mathcal{L}}
\newcommand{\prob}[3]{{#1}_{#2} \left( #3 \right)}
\newcommand{\condprob}[4]{{#1}_{#2} \left( #3 \middle| #4 \right)}
\newcommand{\expected}[2]{\mathbb{E}_{#1}\left[ #2 \right]}
\newcommand{\KL}[2]{D_{\mathrm{KL}}\left( #1 \| #2 \right)}
\newcommand{\pp}{\theta}
\newcommand{\x}{\mathbf{x}}
\newcommand{\z}{\mathbf{z}}
\newcommand{\layers}{L}
\newcommand{\dimpp}{D}
$$

</div>


    <section class="main-content">
      <h1 id="improving-the-prior">Improving the Prior</h1>

<p>Just as we can modify the approximate posterior to fit the prior better, we can also modify the prior such that it is learned from the data.</p>

<p>The expressivity of neural networks and developments in improving the posteriors allow the data to be mapped really well to simple priors like a Gaussian.
So if we can already modify the posterior, why bother changing the prior?
One reason may be due to discontinuity when interpolating in the latent space.
If we imagine each colour code to be a different modality in the data, moving from one colour group to another will represent a drastic change in the type of data decoded <!---CW: talk about inductive bias-->. 
This means that sampling from close regions in the latent space may not represent close relationships in the data space.
Allowing the prior to model a lower density between these different modalities may be more ideal when the type of representation learned is more important than simply sampling data points from the model.</p>

<p><a href="#tomczak2017vae">(Tomczak &amp; Welling, 2017)</a> proposes parameterising the prior as a mixture over a sample of the dataset, or using learned <em>pseudo-inputs</em>. <a href="#serban2016multi">(Serban, Ororbia, Alexander, Pineau, &amp; Courville, 2016)</a> introduces a prior parameterised by a piece-wise linear function. In <a href="#huang2017led">(Huang et al., 2017)</a>, the authors parameterise the prior with Real NVP transformations <a href="#dinh2016density">(Dinh, Sohl-Dickstein, &amp; Bengio, 2016)</a>.</p>

      <h2> What's next? </h2>
      <ul>
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
            <li><a href="/pages/improving_likelihood.html">Improving the Likelihood</a></li>
        
      
        
        
            <li><a href="/pages/improving_pos.html">Improving the Posterior</a></li>
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
      </ul>
      <h2> References </h2>
      <ol class="bibliography"><li><span id="tomczak2017vae">Tomczak, J. M., &amp; Welling, M. (2017). VAE with a VampPrior. <i>ArXiv Preprint ArXiv:1705.07120</i>.</span></li>
<li><span id="serban2016multi">Serban, I. V., Ororbia, I. I., Alexander, G., Pineau, J., &amp; Courville, A. (2016). Multi-modal variational encoder-decoders. <i>ArXiv Preprint ArXiv:1612.00377</i>.</span></li>
<li><span id="huang2017led">Huang, C.-W., Touati, A., Dinh, L., Drozdzal, M., Havaei, M., Charlin, L., &amp; Courville, A. (2017). Learnable Explicit Density for Continuous Latent Space and Variational Inference. <i>ArXiv e-Prints</i>.</span></li>
<li><span id="dinh2016density">Dinh, L., Sohl-Dickstein, J., &amp; Bengio, S. (2016). Density estimation using Real NVP. <i>ArXiv Preprint ArXiv:1605.08803</i>.</span></li></ol>
      <footer class="site-footer">
  <span class="site-footer-credits"><a href="https://mila.umontreal.ca">MILA: Montreal Institute for Learning Algorithms</a></span>
  <span class="site-footer-owner"><a href="">VAEriants</a> is maintained by <a href="https://blog.wtf.sg">Shawn Tan</a>.</span>
  <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/pietromenna/jekyll-cayman-theme">Cayman theme</a> by <a href="http://github.com/jasonlong">Jason Long</a>.</span>
</footer>

    </section>

  </body>
</html>
