<!DOCTYPE html>
<html lang="en-us">
  <head>
  <meta charset="UTF-8">
  <title>VAEriants</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="theme-color" content="#157878">
  <link rel="stylesheet" href="/css/normalize.css">
  <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
  <link rel="stylesheet" href="/css/cayman.css">
  <script type="text/javascript" 
    src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML">
	MathJax.Hub.Config({
	  tex2jax: {
		displayMath: [ ['$$','$$'], ['\[','\]'] ],
		inlineMath: [['$','$'], ['\\(','\\)']],
		processEscapes: true
	  }
	});

  </script>
</head>

  <body>
  <section class="post-header">
	<img src="/assets/mila_logo_fr.svg">
	<a href="/" class="project-name">VAEriants</a>
</section>
<div style="display:none">

$$
\newcommand{\R}{\mathbb{R}}
\newcommand{\D}{\mathcal{D}}
\newcommand{\X}{\mathcal{X}}
\newcommand{\Y}{\mathcal{Y}}
\newcommand{\h}{h}
\newcommand{\N}{\mathcal{N}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\ELBO}{\mathcal{L}}
\newcommand{\prob}[3]{{#1}_{#2} \left( #3 \right)}
\newcommand{\condprob}[4]{{#1}_{#2} \left( #3 \middle| #4 \right)}
\newcommand{\expected}[2]{\mathbb{E}_{#1}\left[ #2 \right]}
\newcommand{\KL}[2]{D_{\mathrm{KL}}\left( #1 \| #2 \right)}
\newcommand{\pp}{\theta}
\newcommand{\x}{\mathbf{x}}
\newcommand{\z}{\mathbf{z}}
\newcommand{\layers}{L}
\newcommand{\dimpp}{D}
$$

</div>


    <section class="main-content">
      <h1 id="an-information-theoretic-intuition">An Information Theoretic Intuition</h1>

<p>For this view, we are trying to minimise the following objective:</p>

<div class="kdmath">$$
\underbrace{-\expected{\condprob{q}{}{\z}{\x}}{\log \condprob{p}{}{\x}{\z}}}_\text{
 Reconstruction loss}
+ \underbrace{\KL{\condprob{q}{}{\z}{\x}}{\log \prob{p}{}{\z}}}_\text{
 Information gain
}
$$</div>

<p>which is the standard VAE loss to <em>minimise</em>.</p>

<p>Karol Gregor explains <a href="https://youtu.be/P78QYjWh5sM?t=207">this lecture</a>. At the timestamp, he talks about an information-theoretic interpretation of the VAE loss. From this perspective, the KL-divergence term is viewed as an information bottleneck: The objective is to reconstruct the input while transmitting as little information as possible from the encoder to the decoder.</p>

<p>Thinking of the KL-divergence term as a regulariser allows us to relate it back to things like sparse autoencoders or contractive autoencoders. The reconstruction term is balanced with a regularisation term on the hidden representation. In a standard autoencoder, the encoder maps $\x$ to the hidden representation deterministically, with no constraints. The decoder then maps this representation back to the original input. In VAEs, the KL-divergence term regularises this representation $\z$ so that in aggregate, they form a Gaussian distribution. See Figure \ref{fig:ae_vs_vae}. This then allows you to sample from the prior $\prob{p}{}{\z}$ which is a Gaussian to generate images similar to your data.</p>

<p>However, one misunderstanding about the KL-divergence term is that it should be close to 0 for a good model. What this interpretation tells us that this shouldn’t be the case: a KL-divergence term close to 0 means no information is being transmitted by the encoder to the decoder. In our running example about salaries, knowing someone’s salary should narrow down which group he belongs to, giving us some <strong>information</strong> about $\z$.</p>

<p>The great thing about looking at it this way is that you can think  of the term as a measurement of information flow that you can monitor during training.  As we will see later, in some circumstances where we have a powerful decoder, the KL-divergence does go to 0. We’ll talk about several ways we can overcome such issues.</p>

<p>This view has been covered in <a href="#higgins2016beta">(Higgins et al., 2016)</a> and <a href="#alemi2017information">(Alemi et al., 2017)</a> in much more detail.</p>


      <h2> What's next? </h2>
      <ul>
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
      </ul>
      <h2> References </h2>
      <ol class="bibliography"><li><span id="higgins2016beta">Higgins, I., Matthey, L., Pal, A., Burgess, C., Glorot, X., Botvinick, M., … Lerchner, A. (2016). beta-vae: Learning basic visual concepts with a constrained variational framework.</span></li>
<li><span id="alemi2017information">Alemi, A. A., Poole, B., Fischer, I., Dillon, J. V., Saurous, R. A., &amp; Murphy, K. (2017). An Information-Theoretic Analysis of Deep Latent-Variable Models. <i>ArXiv Preprint ArXiv:1711.00464</i>.</span></li></ol>
      <footer class="site-footer">
  <span class="site-footer-credits"><a href="https://mila.umontreal.ca">MILA: Montreal Institute for Learning Algorithms</a></span>
  <span class="site-footer-owner"><a href="">VAEriants</a> is maintained by <a href="https://blog.wtf.sg">Shawn Tan</a>.</span>
  <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/pietromenna/jekyll-cayman-theme">Cayman theme</a> by <a href="http://github.com/jasonlong">Jason Long</a>.</span>
</footer>

    </section>

  </body>
</html>
